{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"congan_train.py\", line 12, in <module>\r\n",
      "    import libs.plot\r\n",
      "  File \"/workspace/improved-wgan-pytorch/libs/plot.py\", line 3, in <module>\r\n",
      "    import matplotlib\r\n",
      "ModuleNotFoundError: No module named 'matplotlib'\r\n"
     ]
    }
   ],
   "source": [
    "!python congan_train.py --train_dir ../data/train --output_path ../data/wgan_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen_rand_noise_with_label(label=None):\n",
    "    if label is None:\n",
    "        label = np.random.randint(0, NUM_CLASSES, BATCH_SIZE)\n",
    "    #attach label into noise\n",
    "    noise = np.random.normal(0, 1, (BATCH_SIZE, 128))\n",
    "    prefix = np.zeros((BATCH_SIZE, NUM_CLASSES))\n",
    "    prefix[np.arange(BATCH_SIZE), label] = 1\n",
    "    noise[np.arange(BATCH_SIZE), :NUM_CLASSES] = prefix[np.arange(BATCH_SIZE)]\n",
    "\n",
    "    noise = torch.from_numpy(noise).float()\n",
    "    noise = noise.to(device)\n",
    "\n",
    "    return noise\n",
    "\n",
    "def generate_image(netG, noise=None):\n",
    "    if noise is None:\n",
    "        rand_label = np.random.randint(0, NUM_CLASSES, BATCH_SIZE)\n",
    "        noise = gen_rand_noise_with_label(rand_label)\n",
    "    with torch.no_grad():\n",
    "        noisev = noise\n",
    "    samples = netG(noisev)\n",
    "    samples = samples.view(BATCH_SIZE, 3, DIM, DIM)\n",
    "\n",
    "    samples = samples * 0.5 + 0.5\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'models/'\n",
    "\n",
    "netG = torch.load(OUTPUT_PATH + \"generator.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'save_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2ff55fd10da1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0msave_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/img%d.png'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mgenerate_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'BCC'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-2ff55fd10da1>\u001b[0m in \u001b[0;36mgenerate_class\u001b[0;34m(netG, label, path)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0msave_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/img%d.png'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mgenerate_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'BCC'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'save_image' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "BATCH_SIZE = 64\n",
    "NUM_CLASSES = 9\n",
    "DIM = 64\n",
    "device = torch.device(\"cuda\")\n",
    "#class = 'AK'\n",
    "TRAINING_CLASS = {'AK':0,'BCC':1,'BKL':2,'DF':3,'MEL':4,'NV':5,'SCC':6,'UNK':7,'VASC':8}\n",
    "def generate_class(netG, label, path='../data/wgan_output'):\n",
    "    label = TRAINING_CLASS[label]\n",
    "    noise = gen_rand_noise_with_label(label=np.ones(BATCH_SIZE, dtype=int)*label)\n",
    "    samples = generate_image(netG, noise)\n",
    "    for i,img in enumerate(samples):\n",
    "        save_image(img, path+'/img%d.png'%i)\n",
    "        \n",
    "generate_class(netG, 'BCC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'noise' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-597533895762>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'noise' is not defined"
     ]
    }
   ],
   "source": [
    "samples = generate_image(netG, noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "from torchvision.utils import save_image\n",
    "for i,img in enumerate(samples):\n",
    "    save_image(img, '../data/wgan_output/img%d.png'%i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
